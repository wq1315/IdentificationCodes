{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789+-=\n"
     ]
    }
   ],
   "source": [
    "from captcha.image import ImageCaptcha\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import string\n",
    "characters = string.digits +'+-='\n",
    "print(characters)\n",
    "import pandas as pd\n",
    "\n",
    "width, height, n_len, n_class = 170, 80, 4, len(characters)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen(batch_size=128):\n",
    "    X = np.zeros((batch_size, width, height, 3), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, n_len,n_class), dtype=np.uint8)\n",
    "    while True:\n",
    "        generator = ImageCaptcha(width=width, height=height)\n",
    "        for i in range(batch_size):\n",
    "            random_str = ''.join([random.choice(characters) for j in range(4)])\n",
    "            X[i] = np.array(generator.generate_image(random_str)).transpose(1, 0, 2)\n",
    "            f = [int(characters.find(x)) for x in random_str]\n",
    "            t = np.zeros((n_len,n_class), dtype=np.uint8)\n",
    "            for index,j in enumerate(f):\n",
    "                t[index,j] = 1\n",
    "            y[i] = t\n",
    "        yield X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "character = string.digits\n",
    "def gen(batch_size=128):\n",
    "    X = np.zeros((batch_size, width, height, 3), dtype=np.uint8)\n",
    "    y = np.zeros((batch_size, n_len,n_class), dtype=np.uint8)\n",
    "    while True:\n",
    "        generator = ImageCaptcha(width=width, height=height)\n",
    "        for i in range(batch_size):\n",
    "            random_str = random.choice(character) + random.choice(['+','-']) + random.choice(character)+'='\n",
    "            X[i] = np.array(generator.generate_image(random_str)).transpose(1, 0, 2)\n",
    "            f = [int(characters.find(x)) for x in random_str]\n",
    "            t = np.zeros((n_len,n_class), dtype=np.uint8)\n",
    "            for index,j in enumerate(f):\n",
    "                t[index,j] = 1\n",
    "            y[i] = t\n",
    "        yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen(1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 170, 80, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 170, 80, 32)       416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 170, 80, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 85, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 85, 40, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 85, 40, 3)         387       \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 4, 2550)           0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 2550)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 4, 218)            4829136   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4, 14)             3066      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 4, 14)             56        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 14)             0         \n",
      "=================================================================\n",
      "Total params: 4,833,317\n",
      "Trainable params: 4,833,161\n",
      "Non-trainable params: 156\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(170,80,3))\n",
    "x = Conv2D(32,(2,2),padding='same',activation='relu')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(2,2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(3,(2,2),padding='same',activation='relu')(x)\n",
    "conv_shape = x.get_shape()\n",
    "x = Reshape((4,-1))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Bidirectional(LSTM(218,return_sequences=True),merge_mode='sum')(x)\n",
    "x = Dense(14)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('softmax')(x)\n",
    "model = Model(input_tensor,x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangqiang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wangqiang/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/wangqiang/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/wangqiang/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/wangqiang/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "    1/51200 [..............................] - ETA: 1:54:49 - loss: 0.0128 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangqiang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/Users/wangqiang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=51200, epochs=1, validation_steps=1280)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200/51200 [==============================] - 5774s 113ms/step - loss: 0.0781 - acc: 0.9758 - val_loss: 0.2480 - val_acc: 0.9191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb461705f8>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen(1), samples_per_epoch=51200, nb_epoch=1,\n",
    "                    validation_data=gen(1), nb_val_samples=1280) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(generator=gen(1),steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = next(gen(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 170, 80, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=80x170 at 0xB25EA1588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(X.reshape(170,80,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_re = model.predict(X,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0mtypekey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'typestr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 80, 3), '|u1')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e69c86870e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_re\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2429\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m             \u001b[0;31m# print(typekey)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type"
     ]
    }
   ],
   "source": [
    "for X,y in gen(1):\n",
    "    data_x = Image.fromarray(X)\n",
    "    a = ''.join([characters[i] for i in [np.argmax(i) for i in y[0]]])\n",
    "    y_re = model.predict(X,steps=1)\n",
    "    b = [np.argmax(i) for i in y_re[0]]\n",
    "    b = ''.join([characters[i] for i in b])\n",
    "    print('y:   ',a)\n",
    "    print('y_pred:    ',b)\n",
    "    print('--------')\n",
    "    if a==b:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7163929600000001"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.92**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
